# Dark Box Test
## Analysis_PMT_darkbox.ipynb
``Analysis_PMT_darkbox.ipynb`` is the script to directly analyze the data named with ``PMT%d_lighton_%d.dat`` or ``PMT%d_dark_%d.dat``, which means the ``PMT%d`` in ``lighton`` or ``dark`` at ``%d`` Volts. The script generates histograms for the pulse areas in both light-on and dark conditions. It also provides information on the gain vs voltage, as well as the photon count for each voltage. To make future analysis easier, it will also generate ``PMT%d_lighton_%d_peaks_area.txt`` or ``PMT%d_dark_%d_peaks_area.txt`` which contains the areas of all peaks it has found in data, and ``PMT%d_lighton.txt`` or ``PMT%d_dark.txt`` that contains the fitting parameters for the histogram of peak area. Beyond the info for peaks and histograms, it will also save ``PMT%d_dark_gain.png`` and ``PMT%d_dark_gain_fit.txt`` for gain information that is directly derived from dark (single-photoelectron) data, and ``PMT%d_Photoelectron_number.png`` derived from fittings of dark and light-on histograms for consistency check.

The purpose of the script can be divided into two parts. Firstly, it is to find peaks in all the data that correspond to either single-photoelectron (dark test) or multi-photoelectron events (light-on test). Secondly, it is to calculate the mean area of these peaks. We know that these peaks in our data correspond to the voltage signal generated by PMT after the photocathode releases an electron or electrons due to the excitement of photons (photoelectron) or other effects (dark events). The integral of the peak (peak area) is proportional to the energy deposited by photons, and if we assume our light source (blue LED) to be monochromatic, then it is proportional to the number of photoelectrons. Therefore, the first step is to find the peaks of interest, calculate their areas and then draw a histogram for peak areas. This histogram can then be used to conduct a Gaussian fit, which will help retrieve the mean and the standard deviation of peak areas. These values are related to the gain and the energy resolution of PMT, respectively. 

Since we fixed the voltage and the frequency we were using in the light-on test, the number of photons in each pulse should be approximately the same, and we can calculate this number by simply dividing the mean area of the light-on test by the mean area of the dark test. The gain of PMT is proportional to the mean area of the dark test, which will explained later in the document, so we can get the gain directly from multiplying a constant to the Gaussian fitting result $\mu$.

Here are the comments for codes:

```
light_on = 0
PMT_num = 1107
testing = 0
voltage_use = [1400, 1500, 1600, 1700, 1800, 1900]
bins_lighton = 100
bins_dark = 50
range_lighton = 12000
range_dark = 600
```
``light_on = 0``: This line is used to track whether a light is on or off, with 0 indicating 'off', which means ``PMT%d_dark_%d.dat``, and 1 indicating 'on', which means ``PMT%d_lighton_%d.dat``. 

``PMT_num = 1107``: This line assigns the value for ``PMT%d`` and further sets the PMT number for titles of plots.

``testing = 0``: This flag indicates whether the program is in testing mode. In testing mode, only 30% of the data is used to save time and memory.

``voltage_use = [1400, 1500, 1600, 1700, 1800, 1900]``: This line is creating a variable named voltage_use and assigning it a list of integers. These values represent different voltage levels to be used in an experiment or test.

``bins_lighton = 100`` and ``bins_dark = 50``: Set the bins for histograms, for the histogram of light-on or dark respectively.

``range_lighton = 12000`` and ``range_dark = 600``: Set the maximum range for histograms (0~range_*), for the histogram of light-on or dark respectively.

```
data = []
if light_on:
    for i in voltage_use:
        file_path = '/raid13/genli/Coherent/PMT_Testing/Testing_%d/PMT%d_lighton_%d.dat' % (PMT_num, PMT_num, i)
        print(file_path)
        data.append(np.fromfile(file_path, dtype=np.int16))
else:
    for i in voltage_use:
        file_path = '/raid13/genli/Coherent/PMT_Testing/Testing_%d/PMT%d_dark_%d.dat' % (PMT_num, PMT_num, i)
        print(file_path)
        data.append(np.fromfile(file_path, dtype=np.int16))
```
Choose the correct ``file_path`` for data. The data read from the files is then appended to the ``data`` list.

```
def get_baseline(data):
    #get median of first 10000 samples
    baseline = np.median(data[0:10000])
    return baseline

def flip_data(data):
    # flip data
    baseline = get_baseline(data)
    data = baseline - data
    return data
```
``flip_data`` code is used to flip a signal around a baseline value.

```
for i in range(len(data)):
    data[i] = flip_data(data[i])
```
All data are flipped and centered at ``baseline = 0``.

For functions ``def find_peaks_lighton(data)`` and ``def find_peaks_dark(data)``, they work very similarly in identifying peaks and calculating their areas, but with some small distinctions referring to the parameters used. So here we will only explain one of them:

```
def find_peaks_lighton(data):
    # find the threshold
    threshold = np.median(np.sort(data[0:int(len(data)*0.2)])[-int(len(data)*0.0002):])
    print('Threshold = ', threshold)
    # find peaks above threshold and higher than the previous and next data points
    peaks = np.where((data > threshold) & (data >= np.roll(data, 1)) & (data >= np.roll(data, -1)) & (data >= np.roll(data, 2)) & (data >= np.roll(data, -2)) & (data >= np.roll(data, 3)) & (data >= np.roll(data, -3)) & (data >= np.roll(data, 4)) & (data >= np.roll(data, -4))& (data >= np.roll(data, 5)) & (data >= np.roll(data, -5)))[0]
    #distance between peaks should be larger than 100
    peaks = peaks[np.where(np.diff(peaks) > 100)[0]]
    # find the start and the end of the peaks
    threshold_width = 0.10*data[peaks]
    start = np.zeros(len(peaks), dtype=int)
    end = np.zeros(len(peaks), dtype=int)
    for i in range(len(peaks)):
        start_t = peaks[i]
        end_t = peaks[i]
        while data[start_t] > threshold_width[i]:
            start_t -= 1
        start[i] = start_t
        while data[end_t] > threshold_width[i]:
            end_t += 1
        end[i] = end_t
    # find the peak height
    height = data[peaks]
    # find the peak width
    width = end - start
    # find the peak area
    area = np.zeros(len(start))
    for i in range(len(start)):
        area[i] = np.sum(data[start[i]:end[i]])
    return peaks, start, end, height, width, area

def find_peaks_dark(data):
    # the threshold is related to the median of top 0.0007% of the data
    threshold = np.median(np.sort(data[0:int(len(data)*0.2)])[-int(len(data)*0.000007):])
    print(len(data)*0.000005)
    length = len(data)
    print('Threshold = ', threshold)
    # find peaks above threshold and higher than the previous and next data points
    peaks = np.where((data > threshold) & (data >= np.roll(data, 1)) & (data >= np.roll(data, -1)) & (data >= np.roll(data, 2)) & (data >= np.roll(data, -2)) & (data >= np.roll(data, 3)) & (data >= np.roll(data, -3)))[0]
    #distance between peaks should be larger than 100
    peaks = peaks[np.where(np.diff(peaks) > 100)[0]]
    # find the start and the end of the peaks
    threshold_width = 0.20*data[peaks]
    start = np.zeros(len(peaks), dtype=int)
    end = np.zeros(len(peaks), dtype=int)
   
    #calculate the area of the peaks
    for i in range(len(peaks)):
        start_t = peaks[i]
        end_t = peaks[i]
        while data[start_t] > threshold_width[i]:
            if (start_t == 0):
                break
            else:
                start_t -= 1
        start[i] = start_t
        while data[end_t] > threshold_width[i]:
            if (end_t == length-1):
                break
            else:
                end_t += 1
        end[i] = end_t 
    #only use peaks with width larger than 0 and smaller than 1000
    shortest = 0
    longest = 1000
    peaks_new = peaks[np.where((end - start > shortest) & (end - start < longest))]
    start_new = start[np.where((end - start > shortest) & (end - start < longest))]
    end_new = end[np.where((end - start > shortest) & (end - start < longest))]
    # find the peak height
    height = data[peaks_new]
    # find the peak width
    width = end_new - start_new
    # find the peak area
    area = np.zeros(len(start_new))
    for i in range(len(start_new)):
        area[i] = np.sum(data[start_new[i]:end_new[i]])
    return peaks_new, start_new, end_new, height, width, area
```

1. It first calculates a threshold value, which is the median of the top 0.02% values in the first 20% of the sorted data.

2. It then identifies peaks in the data. A peak is defined as a data point that is greater than the threshold and also greater than or equal to its immediate five neighbors on either side.

3. It further refines the peaks by ensuring that the distance between consecutive peaks is more than 100.

4. It then identifies the start and end of each peak. The start and end of a peak are defined as the points where the data value drops below 10% of the peak value.

5. It calculates the height of each peak, which is simply the data value at the peak.

6. It calculates the width of each peak, which is the difference between the end and start of the peak.

7. It calculates the area under each peak, which is the sum of the data values between the start and end of the peak.

8. Finally, it returns the peaks, start, end, height, width, and area of each peak.

``threshold`` in ``def find_peaks_lighton(data)`` can be chosen easily since the peaks (signal for multi-photoelectron in light-on test) are significant, however in the case of ``def find_peaks_dark(data)``, peaks for single-photoelectron are subtle and can vary a lot between different PMTs. This is why we designed the function to be "self-adaptive". Instead of using a fixed value, we use the median of a certain percentage of data. ``0.000007`` in ``def find_peaks_dark(data)`` is a crucial parameter and it is chosen based on both reasonable estimation and also experience. The dark rate is $~1000Hz$, and the width of peaks is around $5 ADC = 4\times 5 ns = 20 ns$, so the total time length of peaks is $2\times 10^{-5} s\sim 10^{-5}s$. Starting from $0.00001$, after some finetuning, we can finally get ``0.000007``, which can maximally pick all the peaks while rejecting the noises.

```
def gaussian(x, a, x0, sigma):
    return a*np.exp(-(x-x0)**2/(2*sigma**2))

def fit_gaussian_lighton(data):
    initial = 50
    hist, bin_edges = np.histogram(data, range=[0,range_lighton],bins=bins_lighton)
    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2 
    bar = np.mean(hist[bin_centers>initial])
    start = []
    end = []
    #find the highest column
    peaks = np.where(hist == np.max(hist[bin_centers>100]))[0]
    print('peaks=', bin_centers[peaks])
    #find the start and end of the first peak
    for j in range(len(peaks)):
        start_t = peaks[j]
        end_t = peaks[j]
        while (hist[start_t] > 0.2*hist[peaks[j]]) & (start_t > 0):
            start_t -= 1
        start.append(start_t)
        while (hist[end_t] > 0.2*hist[peaks[j]]) & (end_t < len(hist)-1):
            end_t += 1
        end.append(end_t)

    print (bin_centers[start[0]], bin_centers[end[0]])
    start_value = bin_centers[start[0]] - 5
    end_value = bin_centers[end[0]] + 5
    print(bin_centers[(bin_centers > start_value)&(bin_centers < end_value)])
    print(hist[(bin_centers > start_value)&(bin_centers < end_value)])
    popt, pcov = curve_fit(gaussian, bin_centers[(bin_centers > start_value)&(bin_centers < end_value)], hist[(bin_centers > start_value)&(bin_centers < end_value)], bounds=([bar, start_value, 10], [np.inf, end_value, 5000]), maxfev=500000)
    return popt, pcov

def fit_gaussian_dark(data):
    hist, bin_edges = np.histogram(data, range=[0,range_dark], bins=bins_dark)
    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2

    start = []
    end = []
    initial = 50
    bar = np.mean(hist[bin_centers>initial])
    #find ROI
    score = hist*np.exp(-bin_centers/300)
    # print('score=', score)
    print('max score=', np.max(score))
    print('ROI_center=', bin_centers[np.where(score == np.max(score))])
    ROI_center = bin_centers[np.where(score == np.max(score))]
    if ROI_center < 50:
        ROI_left = 0
    else:
        ROI_left = ROI_center - 50
    ROI_right = ROI_center + 50
    #find the highest column in ROI
    peaks = np.where(hist == np.max(hist[(bin_centers > ROI_left)&(bin_centers < ROI_right)]))[0]
    print('peaks=', bin_centers[peaks])
    print('hist=', hist[peaks])
     #find the start and end of the first peak
    for j in range(len(peaks)):
        start_t = peaks[j]
        end_t = peaks[j]
        while (hist[start_t] > 0.2*hist[peaks[j]]) & (start_t > 0):
            start_t -= 1
        start.append(start_t)
        while (hist[end_t] > 0.2*hist[peaks[j]]) & (end_t < len(hist)-1):
            end_t += 1
        end.append(end_t)

    print (bin_centers[start[0]], bin_centers[end[0]])
    start_value = bin_centers[start[0]] - 5
    end_value = bin_centers[end[0]] + 5
    print(bin_centers[(bin_centers > start_value)&(bin_centers < end_value)])
    print(hist[(bin_centers > start_value)&(bin_centers < end_value)])
    popt, pcov = curve_fit(gaussian, bin_centers[(bin_centers > start_value)&(bin_centers < end_value)], hist[(bin_centers > start_value)&(bin_centers < end_value)], bounds=([bar, start_value, 1], [np.inf, end_value, 200]), maxfev=500000)
    return popt, pcov, start_value, end_value
```
``fit_gaussian_lighton`` and ``fit_gaussian_dark`` are functions to fit the first significant spike in the histogram with Gaussian. Two functions are very similar, so we will only explain ``fit_gaussian_dark``.
1. It first creates a histogram of the data using np.histogram. The range and number of bins for the histogram are defined by range_dark and bins_dark, respectively.

2. It calculates the bin centers by averaging the bin edges.

3. It initializes empty lists for start and end, and sets an initial value of 50.

4. It calculates a bar value, which is the mean of the histogram values where the bin centers are greater than the initial value.

5. It calculates a score for each bin, which is the product of the histogram value and an exponential decay function of the bin center.

6. It identifies the ROI_center as the bin center where the score is maximum.

7. It defines a region of interest (ROI) around the ROI_center, extending 50 units to the left and right.

8. It identifies the peaks within the ROI as the bins where the histogram value is maximum.

9. It finds the start and end of each peak within the ROI. The start and end of a peak are defined as the points where the histogram value drops below 20% of the peak value.

10. It defines a start_value and end_value for the Gaussian fit, which are 5 units less than the start and 5 units more than the end of the first peak, respectively.

11. It fits a Gaussian function to the histogram values within the range defined by start_value and end_value using the curve_fit function from the scipy library. The bounds for the fit parameters and the maximum number of function evaluations are also specified.

12. Finally, it returns the optimal parameters for the fit (popt), the estimated covariance of popt (pcov), and the start_value and end_value for the fit.

```
if light_on == 0:
    Gain_value = 243695.3808 * np.array(mean)
    #fit the gain with exponential function
    def exponential(x, a, b):
        return a* np.exp (b*np.array(x))

    popt, pcov = curve_fit(exponential, voltage_use, Gain_value, maxfev=100000, bounds=([1000, 0], [np.inf, 0.01]))
    print('popt=', popt)
    print('pcov=', pcov)
    plt.figure(figsize=(20, 12))
    plt.plot(voltage_use, Gain_value, 'o', markersize=15)
    x_fit = np.linspace(1400, 2000, 1000)
    plt.plot(x_fit, exponential(x_fit, *popt), label='fit $y=ae^{bx}$, a = %.2f, b = %.4f'%(popt[0], popt[1]), linewidth=3)
    plt.xlabel('Voltage', fontsize=25)
    plt.ylabel('Gain ($10^7$)', fontsize=25)
    plt.title('PMT%d Gain vs Voltage'%PMT_num, fontsize=25)
    plt.legend(fontsize=25)
    plt.xticks(fontsize=25)
    plt.yticks(fontsize=25)
    #save figure
    plt.savefig('PMT%d_dark_gain.png'%PMT_num)
    f = open('PMT%d_dark_gain_fit.txt'%PMT_num, 'w')
    f.write('popt={}\n'.format(popt))
    f.write('pcov={}\n'.format(pcov))
```
The main goal here is to calculate gain and fit gain vs voltage with the exponential function. One key point that requires explanation is that ``Gain_value`` is proportional to ``mean`` ($\mu$ from Gaussian fit). The reason is that the gain is proportional to the mean area of single-photoelectron peaks. Here are the reasons:

![image](https://github.com/GenDustman/PMT_Test_Scripts/assets/99235643/f02e1dc4-d4dc-4a80-952c-04c759d6fcda)

To connect the mean area of single-photoelectron peaks and the gain, a constant is needed. First, we need to convert the area from ADC unit to SI unit, and then divide it by $eR$. Here we list the parameter we are using in this experiment: $1ADC_{time}=4ns$, $1ADC_{voltage}=\frac{2V}{4096}=0.488mV$, $R=50\Omega$, $e = 1.602\times 10^{-19} C$. From here, you can derive the constant to be ``243695.3808``. The calculation has been done in the ``analysis.xlsx`` located in this folder.

```
#plot the photon number vs voltage

#read the mean of dark peak area from txt file PMT%d_dark.txt
mean_dark = []
sigma_dark = []
try:
    f = open('PMT%d_dark.txt'%PMT_num, 'r')
    lines = f.readlines()
    for line in lines:
        if 'Mean of peak area for' in line:
            mean_dark.append(float(line.split(' ')[-1]))
        if 'Sigma of peak area for' in line:
            sigma_dark.append(float(line.split(' ')[-1]))
    print(mean_dark)
    print(sigma_dark)
except:
    print('No dark file')

#try to open the lighton file
mean_lighton = []
sigma_lighton = []
try:
    f = open('PMT%d_lighton.txt'%PMT_num, 'r')
    lines = f.readlines()
    for line in lines:
        if 'Mean of peak area' in line:
            mean_lighton.append(float(line.split(' ')[-1]))
        if 'Sigma of peak area' in line:
            sigma_lighton.append(float(line.split(' ')[-1]))
        
    print(mean_lighton)
    print(sigma_lighton)
except:
    print('No lighton file')

#calculate the photon number
if len(mean_dark) == len(mean_lighton):
    photon_number = np.array(mean_lighton)/np.array(mean_dark)
    print(photon_number)
    errorbar = photon_number * np.sqrt((np.array(sigma_lighton)/np.array(mean_lighton))**2 + (np.array(sigma_dark)/np.array(mean_dark))**2)
    plt.figure(figsize=(20, 12))
    # plt.plot(voltage_use, photon_number, 'o', markersize=15)
    plt.errorbar(voltage_use, photon_number, yerr=errorbar, fmt='o', markersize=15, capsize=5, elinewidth=2, markeredgewidth=2)
    plt.ylim(0, 40)
    plt.xlabel('Voltage', fontsize=25)
    plt.ylabel('Photoelectron number', fontsize=25)
    plt.title('PMT%d Photoelectron number vs Voltage'%PMT_num, fontsize=25)
    plt.xticks(fontsize=25)
    plt.yticks(fontsize=25)
    #save figure
    plt.savefig('PMT%d_Photoelectron_number.png'%PMT_num)
else:
    print('No lighton file or dark file')
```
After analyzing the dark and light-on files, we will get "PMT%d_dark.txt" and "PMT%d_lighton.txt". This cell will retrieve the mean and standard deviation and generate the "PMT%d_Photoelectron_number.png".

## Comparison_darkbox.ipynb
The purpose of this script is straight-forward: to retrieve ``propt`` and ``pcov`` from "PMT%d_dark.txt" and "PMT%d_lighton.txt", and draw the plots of gain vs voltage and the resolution for all PMTs. However, PMT 1117 doesn't have the single-photoelectron signal at 1400V, and the error of fitting is not applicable for both 1400V and 1500V, which may cause some subtleties in plotting but nothing essential.














